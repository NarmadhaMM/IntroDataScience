WAIC = FALSE, iter = 5000, warmup = 1000, chains = 2, cores = 2,
control = list(adapt_delta = 0.95))
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
Sys.setenv(TZ="UTC")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
library(rethinking)
data(UCBadmit)
d <- UCBadmit
d
d$male <- ifelse( d$applicant.gender=="male" , 1 , 0 )
m10.6 <- map(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a + bm*male ,
a ~ dnorm(0,10) ,
bm ~ dnorm(0,10)
) ,
data=d )
m10.7 <- map(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a ,
a ~ dnorm(0,10)
) ,
data=d )
formatR::tidy_app()
compare( m10.6 , m10.7 )
precis(m10.6)
post <- extract.samples( m10.6 )
p.admit.male <- logistic( post$a + post$bm )
p.admit.female <- logistic( post$a )
diff.admit <- p.admit.male - p.admit.female
quantile( diff.admit , c(0.025,0.5,0.975) )
postcheck( m10.6 , n=1e4 )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
x <- 1 + 2*(i-1)
y1 <- d$admit[x]/d$applications[x]
y2 <- d$admit[x+1]/d$applications[x+1]
lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
d$dept_id <- coerce_index( d$dept )
# 对于每个院系拟合单独的截距
m10.8 <- map(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[dept_id] ,
a[dept_id] ~ dnorm(0,10)
) , data=d )
# 加上male这个变量再次拟合模型
m10.9 <- map(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[dept_id] + bm*male ,
a[dept_id] ~ dnorm(0,10) ,
bm ~ dnorm(0,10)
) , data=d )
compare( m10.6 , m10.7 , m10.8 , m10.9 )
precis( m10.9 , depth=2 )
bookdown::render_book("index.Rmd", "bookdown::gitbook")
rsq <- read.csv("/Data/ResponseError.csv")
rsq <- read.csv("Data/ResponseError.csv")
rsq <- read.csv("Data/ResponseError.csv")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
rsq <- read.csv("Data/ResponseError.csv")
selectId <- maxDissim(start, samplePool, obj = minDiss, n = 5)
install.packages("proxy")
selectId <- maxDissim(start, samplePool, obj = minDiss, n = 5)
minDissSet <- samplePool[selectId, ]
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
warnings()
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
cust.df <- read.csv("http://goo.gl/PmPkaG")
str(cust.df)
#find columns with missing values
colSums(is.na(cust.df))
#replace missing satisfaction service/selection values with mean
cust.df$sat.service[is.na(cust.df$sat.service)] = round (mean(cust.df$sat.service, na.rm = TRUE))
cust.df$sat.selection[is.na(cust.df$sat.selection)] = round (mean(cust.df$sat.selection, na.rm = TRUE))
#change email into a binary variable
#Make two new columns 'total.spend' that contains a sum of online and store spending for each customer,
#total.trans that is the sum of online.trans and store.trans
#and average spending ammount by customers: online and instore
table(cust.df$email)
cust.df<- cust.df %>% mutate(email = ifelse(email == "yes",1,0))
cust.df<- cust.df %>% mutate(total.spend = (online.spend + store.spend)) %>%
mutate(total.trans = (online.trans+store.trans))
plot(jitter(cust.df$sat.service), jitter(cust.df$sat.selection),
xlab="Customer Satisfaction with Service",
ylab="Customer Satisfaction with Selection",
main="Customers as of June 2014")
hist(cust.df$total.spend)
describe(cust.df)
hist(log(cust.df$total.spend))
385/455
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
2.98*12
2.08*12
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
source("https://raw.githubusercontent.com/happyrabbit/CE_JSM2017/master/Rcode/00-course-setup.R")
sim.dat$age[which(sim.dat$age>100)]<-NA
sim.dat$store_exp[which(sim.dat$store_exp<0)]<-NA
# see the results
summary(subset(sim.dat,select=c("age","income")))
# save the result as another object
demo_imp<-impute(sim.dat,method="median/mode")
# check the first 5 columns, there is no missing values in other columns
summary(demo_imp[,1:5])
imp<-preProcess(sim.dat,method="medianImpute")
demo_imp2<-predict(imp,sim.dat)
summary(demo_imp2[,1:5])
imp<-preProcess(sim.dat,method="knnImpute",k=5)
# need to use predict() to get KNN result
demo_imp<-predict(imp,sim.dat)
summary(demo_imp)
0.8^2+0.8^4+0.8^2-0.2*0.8^5
(0.8^2+0.8^4+0.8^2-0.2*0.8^5)/3
(0.8^1+0.8^3+0.8^2-0.2*0.8^4)/3
17/4
5/1.6
36/19*31
source('~/.active-rstudio-document', echo=TRUE)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
<<<<<<< HEAD
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
getwd()
install.packages("googlesheets")
?googlesheets::gs_url
tt = googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1dY8wETaUkBbiOylwkPYOlg6LnDJa2f_xDy9jpt1opQ0/edit#gid=0")
tt = googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1dY8wETaUkBbiOylwkPYOlg6LnDJa2f_xDy9jpt1opQ0/edit#gid=0")
tt = googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1dY8wETaUkBbiOylwkPYOlg6LnDJa2f_xDy9jpt1opQ0/edit?usp=sharing")
tt = googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1dY8wETaUkBbiOylwkPYOlg6LnDJa2f_xDy9jpt1opQ0/edit?usp=sharing")
tt = googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1dY8wETaUkBbiOylwkPYOlg6LnDJa2f_xDy9jpt1opQ0/edit?usp=sharing")
6500*12
7000*12
=======
>>>>>>> 08a9ea43827300d8f05b15819a9c9cc5e56cec26
17500*0.73
5100*12
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
c(1.59,1.45)/sum(c(1.59,1.45))
bookdown::render_book("index.Rmd", "bookdown::gitbook")
plotly::subplot()
plotly::subplot
1/12
NetlifyDS::impute_dat
devtools::install_github("hrbrmstr/slackr")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
sqrt(4)
20/70
20/70*80
20/70*90
67/94
166*0.3
require(RCurl)
u <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vT5o04RE2sSqFGbA_iyhjAUYDE3TpGXzQMjyBrMvHUk1RpSDJ22SB0F7SLMoqXim5hn733oHYYsok0s/pub?gid=0&single=true&output=csv"
tc <- getURL(u, ssl.verifypeer=FALSE)
net <- read.csv(textConnection(tc))
View(net)
g <- readGoogleSheet(u)
install.packages("googlesheet")
library(googlesheet)
?getURL
tc <- getURL(u, ssl.verifypeer=FALSE, .encoding = "CE_UTF8")
net <- read.csv(textConnection(tc))
View(net)
# Budget
closing_cost = 334014
deposit = 22440
month_pay = 2453
hoa = 557
tax = 748000 * 0.0116/12
# Monthly life cost here in bay area
month_house = month_pay + hoa + tax
still_need = closing_cost - deposit
month_house
hoa + tax
month_house/7000
month_house/10000
# Aug 1
coming = 568*2 + 3500*5
coming
cash_now + from_parents + coming - still_need
cash_now = 356169
from_parents = 25000
# Aug 1
coming = 568*2 + 3500*5
cash_now + from_parents + coming - still_need
cash_now = 356169
from_parents = 25000
# Aug 1
coming = 568*2 + 3500*5
cash_now + from_parents + coming - still_need
1156 + 1500 + 100
50*4
50*4 + 150 + 51 + 36 + 30
50*4 + 150 + 51 + 36 + 30 + 200
50*4 + 150 + 51 + 36 + 30 + 100
2*17500
4*17500
7000*12
7000*12 - 30000
(7000*12 - 30000)*3
(7000*12 - 30000)*7
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
36.99*7
2500*12
5.86*20000
6*20000
6*17500
40*7
20*7
5.86/7
formatR::tidy_app()
sim.dat <- read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv ")
summary(sim.dat)
head(sim.dat)
head(sim.dat)
str(sim.dat)
summary(sim.dat)
formatR::tidy_app()
# set problematic values as missings
sim.dat$age[which(sim.dat$age > 100)] <- NA
sim.dat$store_exp[which(sim.dat$store_exp < 0)] <- NA
# see the results
summary(subset(sim.dat, select = c("age", "income")))
demo_imp<-impute(sim.dat,method="median/mode")
# check the first 5 columns, there is no missing values in other columns
summary(demo_imp[,1:5])
sim.dat <- read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv ")
summary(sim.dat)
sim.dat$age[which(sim.dat$age > 100)] <- NA
sim.dat$store_exp[which(sim.dat$store_exp < 0)] <- NA
# see the results
summary(subset(sim.dat, select = c("age", "income")))
summary(subset(sim.dat, select = c("age", "store_exp")))
demo_imp<-impute(sim.dat,method="median/mode")
# check the first 5 columns, there is no missing values in other columns
summary(demo_imp[,1:5])
library(imputeMissings)
# save the result as another object
demo_imp<-impute(sim.dat,method="median/mode")
# check the first 5 columns, there is no missing values in other columns
summary(demo_imp[,1:5])
imp<-preProcess(sim.dat,method="medianImpute")
demo_imp2<-predict(imp,sim.dat)
summary(demo_imp2[,1:5])
imp <- preProcess(sim.dat, method = "medianImpute")
demo_imp2 <- predict(imp, sim.dat)
summary(demo_imp2[, 1:5])
library(caret)
imp <- preProcess(sim.dat, method = "medianImpute")
demo_imp2 <- predict(imp, sim.dat)
summary(demo_imp2[, 1:5])
demo_imp <- impute(sim.dat, method = "median/mode")
# check the first 5 columns, there is no missing values in other columns
summary(demo_imp[, 1:5])
imp <- preProcess(sim.dat, method = "medianImpute")
demo_imp2 <- predict(imp, sim.dat)
summary(demo_imp2[, 1:5])
sim.dat[, 1:5]
summary(sim.dat[, 1:5])
imp<-preProcess(sim.dat,method="knnImpute",k=5)
# need to use predict() to get KNN result
demo_imp<-predict(imp,sim.dat)
summary(demo_imp[,1:3])
imp<-preProcess(sim.dat,method="knnImpute",k=5)
idx<-which(lapply(sim.dat,class)=="factor")
demo_imp<-predict(imp,sim.dat[,-idx])
summary(demo_imp[,1:3])
temp<-rbind(sim.dat,rep(NA,ncol(sim.dat)))
imp<-preProcess(sim.dat,method="knnImpute",k=5)
idx<-which(lapply(temp,class)=="factor")
predict(imp,temp)
idx <- apply(temp, 1, function(x) sum(is.na(x)))
as.vector(which(idx == ncol(temp)))
imp<-preProcess(sim.dat,method="bagImpute")
demo_imp<-predict(imp,sim.dat)
summary(demo_imp[,1:5])
sdat <- subset(sim.dat, select = c("age", "income"))
# set the 'method' option
trans <- preProcess(sdat, method = c("center", "scale"))
# use predict() function to get the final result
transformed <- predict(trans, sdat)
summary(transformed)
# skew, fig.cap='Shewed Distribution', out.width='80%', fig.asp=.75, # fig.align='center'
# need skewness() function from e1071 package
set.seed(1000)
par(mfrow=c(1,2),oma=c(2,2,2,2))
# random sample 1000 chi-square distribution with df=2
# right skew
x1<-rchisq(1000,2, ncp = 0)
# get left skew variable x2 from x1
x2<-max(x1)-x1
plot(density(x2),main=paste("left skew, skewnwss =",round(skewness(x2),2)), xlab="X2")
plot(density(x1),main=paste("right skew, skewness =",round(skewness(x1),2)), xlab="X1")
library(e1071)
# skew, fig.cap='Shewed Distribution', out.width='80%', fig.asp=.75, # fig.align='center'
# need skewness() function from e1071 package
set.seed(1000)
par(mfrow=c(1,2),oma=c(2,2,2,2))
# random sample 1000 chi-square distribution with df=2
# right skew
x1<-rchisq(1000,2, ncp = 0)
# get left skew variable x2 from x1
x2<-max(x1)-x1
plot(density(x2),main=paste("left skew, skewnwss =",round(skewness(x2),2)), xlab="X2")
plot(density(x1),main=paste("right skew, skewness =",round(skewness(x1),2)), xlab="X1")
# skew, fig.cap='Shewed Distribution', out.width='80%', fig.asp=.75, # fig.align='center'
# need skewness() function from e1071 package
set.seed(1000)
par(mfrow=c(1,2),oma=c(2,2,2,2))
# random sample 1000 chi-square distribution with df=2
# right skew
x1<-rchisq(1000,2, ncp = 0)
# get left skew variable x2 from x1
x2<-max(x1)-x1
plot(density(x2),main=paste("left skew, skewnwss =",round(skewness(x2),2)), xlab="X2")
plot(density(x1),main=paste("right skew, skewness =",round(skewness(x1),2)), xlab="X1")
describe(sim.dat)
??describe
library(psych)
describe(sim.dat)
DescTools::Desc(sim.dat)
describe(sim.dat)
describe(sim.dat)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
# install packages from CRAN
p_needed <- c('imputeMissings','caret','e1071','psych')
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
lapply(p_needed, require, character.only = TRUE)
lapply(p_needed, require, character.only = F)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
describe(sim.dat)
describe(sim.dat)
transformed<-predict(trans,dat_bc)
par(mfrow=c(1,2),oma=c(2,2,2,2))
hist(dat_bc$store_trans,main="Before Transformation",xlab="store_trans")
hist(transformed$store_trans,main="After Transformation",xlab="store_trans")
dat_bc <- subset(sim.dat, select = c("store_trans", "online_trans"))
(trans <- preProcess(dat_bc, method = c("BoxCox")))
transformed<-predict(trans,dat_bc)
par(mfrow=c(1,2),oma=c(2,2,2,2))
hist(dat_bc$store_trans,main="Before Transformation",xlab="store_trans")
hist(transformed$store_trans,main="After Transformation",xlab="store_trans")
transformed<-predict(trans,dat_bc)
par(mfrow=c(1,2),oma=c(2,2,2,2))
hist(dat_bc$store_trans,main="Before Transformation",xlab="store_trans")
hist(transformed$store_trans,main="After Transformation",xlab="store_trans")
(trans<-BoxCoxTrans(dat_bc$store_trans))
dat_bc <- subset(sim.dat, select = c("store_trans", "online_trans"))
(trans <- preProcess(dat_bc, method = c("BoxCox")))
sdat<-subset(sim.dat,select=c("age","income","store_exp","online_exp","store_trans","online_trans" ))
# use scatterplotMatrix() function from car package
par(oma=c(2,2,1,2))
scatterplotMatrix(sdat,diagonal="boxplot",smoother=FALSE)
# calculate median of the absolute dispersion for income
ymad<-mad(na.omit(sdat$income))
# calculate z-score
zs<-(sdat$income-mean(na.omit(sdat$income)))/ymad
# count the number of outliers
sum(na.omit(zs>3.5))
# KNN imputation
sdat<-sim.dat[,c("income","age")]
imp<-preProcess(sdat,method=c("knnImpute"),k=5)
sdat<-predict(imp,sdat)
transformed <- spatialSign(sdat)
transformed <- as.data.frame(transformed)
par(mfrow=c(1,2),oma=c(2,2,2,2))
plot(income ~ age,data = sdat,col="blue",main="Before")
plot(income ~ age,data = transformed,col="blue",main="After")
# KNN imputation
sdat<-sim.dat[,c("income","age")]
imp<-preProcess(sdat,method=c("knnImpute"),k=5)
sdat<-predict(imp,sdat)
transformed <- spatialSign(sdat)
transformed <- as.data.frame(transformed)
par(mfrow=c(1,2),oma=c(2,2,2,2))
plot(income ~ age,data = sdat,col="blue",main="Before")
plot(income ~ age,data = transformed,col="blue",main="After")
# KNN imputation
sdat<-sim.dat[,c("income","age")]
imp<-preProcess(sdat,method=c("knnImpute"),k=5)
sdat<-predict(imp,sdat)
transformed <- spatialSign(sdat)
transformed <- as.data.frame(transformed)
par(mfrow=c(1,2),oma=c(2,2,2,2))
plot(income ~ age,data = sdat,col="blue",main="Before")
plot(income ~ age,data = transformed,col="blue",main="After")
(highCorr <- findCorrelation(cor(sdat), cutoff = 0.75))
# select non-survey numerical variables
sdat <- subset(sim.dat, select = c("age", "income", "store_exp", "online_exp",
"store_trans", "online_trans"))
# use bagging imputation here
imp <- preProcess(sdat, method = "bagImpute")
sdat <- predict(imp, sdat)
# get the correlation matrix
correlation <- cor(sdat)
# plot
par(oma = c(2, 2, 2, 2))
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
par(oma = c(2, 2, 2, 2))
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
plot.new()
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
(highCorr <- findCorrelation(cor(sdat), cutoff = 0.75))
sdat <- subset(sim.dat, select = c("age", "income", "store_exp", "online_exp",
"store_trans", "online_trans"))
# use bagging imputation here
imp <- preProcess(sdat, method = "bagImpute")
sdat <- predict(imp, sdat)
# get the correlation matrix
correlation <- cor(sdat)
correlation
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
par(oma = c(2, 2, 2, 2))
corrplot.mixed(correlation, order = "hclust", tl.pos = "lt", upper = "ellipse")
correlation
correlation['online_trans','age']
(highCorr <- findCorrelation(cor(sdat), cutoff = 0.7))
# delete highly correlated columns
sdat<-sdat[-highCorr]
# check the new correlation matrix
cor(sdat)
nearZeroVar(zero_demo,freqCut = 95/5, uniqueCut = 10)
dumVar <- nnet::class.ind(sim.dat$gender)
head(dumVar)
dumMod<-dummyVars(~gender+house+income,
data=sim.dat,
# use "origional variable name + level" as new name
levelsOnly=F)
head(predict(dumMod,sim.dat))
bookdown::render_book("index.Rmd", "bookdown::gitbook")
summary(sim.dat)
summary(sim.dat)
summary(sim.dat)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
sim.dat <- read.csv("http://bit.ly/2P5gTw4")
summary(sim.dat)
rating<-read.csv("http://bit.ly/2TNQ6TK")
str(rating,vec.len=3)
disease_dat<-read.csv("http://bit.ly/2KXb1Qi")
head(subset(disease_dat,select=c("Q118.A","Q118.B","Q119.A",
"Q119.B","Q120.A","Q120.B","y")))
